{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a82795c-b164-4140-8473-1d626567bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from numbers import Integral, Real\n",
    "import scipy.sparse as sp\n",
    "from scipy.special import expit, softmax  # logistic function\n",
    "\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.base import (\n",
    "    BaseEstimator,\n",
    "    ClassNamePrefixFeaturesOutMixin,\n",
    "    TransformerMixin,\n",
    "    _fit_context,\n",
    ")\n",
    "from sklearn.utils import check_random_state, gen_even_slices\n",
    "from sklearn.utils._param_validation import Interval\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "class RBM(BernoulliRBM):\n",
    "    def __init__(self, n_components=2, learning_rate=0.1, batch_size=10, n_iter=10, verbose=0, random_state=None, add_bias=False, target_in_model=False, input_dist='bernoulli', latent_dist='bernoulli',target_dist='gaussian'):\n",
    "        super().__init__(n_components=n_components, learning_rate=learning_rate,\n",
    "                         batch_size=batch_size, n_iter=n_iter, verbose=verbose, random_state=random_state)\n",
    "        self.add_bias = add_bias\n",
    "        self.input_dist = input_dist # 'bernoulli' or 'gaussian'\n",
    "        self.latent_dist = latent_dist # 'bernoulli' or 'multinomial'\n",
    "        self.target_dist = target_dist # 'bernoulli' or 'gaussian'\n",
    "        self.target_in_model = target_in_model\n",
    "\n",
    "    def transform(self, X, y):\n",
    "        \"\"\"Compute the hidden layer activation probabilities, P(h=1|v=X).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            The data to be transformed.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        h : ndarray of shape (n_samples, n_components)\n",
    "            Latent representations of the data.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self)\n",
    "        # X = self._validate_data(\n",
    "        #     X, accept_sparse=\"csr\", reset=False, dtype=(np.float64, np.float32)\n",
    "        # )\n",
    "        return self._mean_hiddens(X, y)\n",
    "\n",
    "    def _mean_hiddens(self, v, t):\n",
    "        \"\"\"Computes the probabilities P(h=1|v).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        v : ndarray of shape (n_samples, n_features)\n",
    "            Values of the visible layer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        h : ndarray of shape (n_samples, n_components)\n",
    "            Corresponding mean field values for the hidden layer.\n",
    "        \"\"\"\n",
    "        if (self.input_dist == 'bernoulli'):\n",
    "            p = safe_sparse_dot(v, self.components_.T)\n",
    "        elif (self.input_dist == 'gaussian'):\n",
    "            p = safe_sparse_dot(v/self.sigma, self.components_.T)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid input distribution: {}\".format(self.input_dist))\n",
    "        \n",
    "        if (self.add_bias):\n",
    "            p += self.intercept_hidden_\n",
    "\n",
    "        if (self.target_in_model):\n",
    "            if (self.target_dist == 'bernoulli'):\n",
    "                p += safe_sparse_dot(t, self.target_components_)\n",
    "            elif (self.target_dist == 'gaussian'):\n",
    "                p += safe_sparse_dot(t/self.target_sigma, self.target_components_)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid target distribution: {}\".format(self.target_dist))\n",
    "        \n",
    "        if (self.latent_dist == 'bernoulli'):\n",
    "            p = expit(p, out=p)\n",
    "        elif (self.latent_dist == 'multinomial'):\n",
    "            p = softmax(p)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid latent distribution: {}\".format(self.latent_dist))\n",
    "        return p\n",
    "\n",
    "    def _sample_hiddens(self, v, t, rng):\n",
    "        \"\"\"Sample from the distribution P(h|v).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        v : ndarray of shape (n_samples, n_features)\n",
    "            Values of the visible layer to sample from.\n",
    "\n",
    "        rng : RandomState instance\n",
    "            Random number generator to use.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        h : ndarray of shape (n_samples, n_components)\n",
    "            Values of the hidden layer.\n",
    "        \"\"\"\n",
    "        p = self._mean_hiddens(v, t)\n",
    "        if (self.latent_dist == 'bernoulli'):\n",
    "            samples = rng.uniform(size=p.shape) < p\n",
    "        elif (self.latent_dist == 'multinomial'):\n",
    "            samples = [rng.multinomial(self.sample_size, pval) for pval in p]\n",
    "            samples = np.array(samples)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid latent distribution: {}\".format(self.latent_dist))\n",
    "        return samples\n",
    "\n",
    "    def _mean_visibles(self, h):\n",
    "        \"\"\"Computes the probabilities P(v=1|h).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : ndarray of shape (n_samples, n_components)\n",
    "            Values of the hidden layer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        v : ndarray of shape (n_samples, n_features)\n",
    "            Corresponding mean field values for the visible layer.\n",
    "        \"\"\"\n",
    "        p = np.dot(h, self.components_)\n",
    "        if (self.input_dist == 'gaussian'):\n",
    "            p *= self.sigma\n",
    "            if (self.add_bias):\n",
    "                p += self.intercept_visible_\n",
    "        elif (self.input_dist == 'bernoulli'):\n",
    "            if (self.add_bias):\n",
    "                p += self.intercept_visible_\n",
    "            p = expit(p, out=p)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid input distribution: {}\".format(self.input_dist))\n",
    "\n",
    "        return p\n",
    "    \n",
    "    def _sample_visibles(self, h, rng):\n",
    "        \"\"\"Sample from the distribution P(v|h).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : ndarray of shape (n_samples, n_components)\n",
    "            Values of the hidden layer to sample from.\n",
    "\n",
    "        rng : RandomState instance\n",
    "            Random number generator to use.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        v : ndarray of shape (n_samples, n_features)\n",
    "            Values of the visible layer.\n",
    "        \"\"\"\n",
    "        p = self._mean_visibles(h)\n",
    "        if (self.input_dist == 'gaussian'):\n",
    "            samples = rng.normal(p, self.sigma, size=p.shape)\n",
    "        elif (self.input_dist == 'bernoulli'):\n",
    "            samples = rng.uniform(size=p.shape) < p\n",
    "        else:\n",
    "            raise ValueError(\"Invalid input distribution: {}\".format(self.input_dist))\n",
    "        return samples\n",
    "\n",
    "    def _mean_targets(self, h):\n",
    "        \"\"\"Computes the probabilities P(t|h).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : ndarray of shape (n_samples, n_components)\n",
    "            Values of the hidden layer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        t : ndarray of shape (n_samples, n_targets)\n",
    "            Corresponding mean field values for the target layer.\n",
    "        \"\"\"\n",
    "        p = np.dot(h, self.target_components_.T)\n",
    "        if (self.target_dist == 'gaussian'):\n",
    "            p *= self.target_sigma\n",
    "            if (self.add_bias):\n",
    "                p += self.intercept_target_\n",
    "        elif (self.target_dist == 'bernoulli'):\n",
    "            if (self.add_bias):\n",
    "                p += self.intercept_target_\n",
    "            p = expit(p, out=p)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid target distribution: {}\".format(self.target_dist))\n",
    "        return p\n",
    "    \n",
    "    def _sample_targets(self, h, rng):\n",
    "        \"\"\"Sample from the distribution P(t|h).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : ndarray of shape (n_samples, n_components)\n",
    "            Values of the hidden layer to sample from.\n",
    "\n",
    "        rng : RandomState instance\n",
    "            Random number generator to use.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        t : ndarray of shape (n_samples, n_targets)\n",
    "            Values of the target layer.\n",
    "        \"\"\"\n",
    "        p = self._mean_targets(h)\n",
    "        if (self.target_dist == 'bernoulli'):\n",
    "            samples = rng.uniform(size=p.shape) < p\n",
    "        elif (self.target_dist == 'gaussian'):\n",
    "            samples = rng.normal(p, self.target_sigma, size=p.shape)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid target distribution: {}\".format(self.target_dist))\n",
    "        return samples\n",
    "    \n",
    "    def _free_energy(self, v, t):\n",
    "        \"\"\"Computes the free energy F(v) = - log sum_h exp(-E(v,h)).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        v : ndarray of shape (n_samples, n_features)\n",
    "            Values of the visible layer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        free_energy : ndarray of shape (n_samples,)\n",
    "            The value of the free energy.\n",
    "        \"\"\"\n",
    "        if (self.add_bias and self.input_dist == 'gaussian'):\n",
    "            input_energy = np.sum(((v - self.intercept_visible_) / self.sigma) ** 2, axis=1) - np.logaddexp(0, safe_sparse_dot(v/(self.sigma ** 2), self.components__.T) + self.intercept_hidden_).sum(axis=1)\n",
    "        elif (self.add_bias and self.input_dist == 'bernoulli'):\n",
    "            input_energy = -safe_sparse_dot(v, self.intercept_visible_) - np.logaddexp(0, safe_sparse_dot(v, self.components_.T) + self.intercept_hidden_).sum(axis=1)\n",
    "        elif (self.input_dist == 'gaussian'):\n",
    "            input_energy = np.sum((v / self.sigma) ** 2, axis=1) - np.logaddexp(0, safe_sparse_dot(v/(self.sigma ** 2), self.components__.T)).sum(axis=1)\n",
    "        elif (self.input_dist == 'bernoulli'):\n",
    "            input_energy = - np.logaddexp(0, safe_sparse_dot(v, self.components_.T)).sum(axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid input distribution: {}\".format(self.input_dist))\n",
    "        \n",
    "        if (self.target_in_model):\n",
    "            if (self.add_bias and self.target_dist == 'gaussian'):\n",
    "                target_energy = np.sum(((t - self.intercept_target_) / self.target_sigma) ** 2, axis=1) - np.logaddexp(0, safe_sparse_dot(t/(self.target_sigma ** 2), self.target_components__) + self.intercept_hidden_).sum(axis=1)\n",
    "            elif (self.add_bias and self.target_dist == 'bernoulli'):\n",
    "                target_energy = -safe_sparse_dot(t, self.intercept_target_) - np.logaddexp(0, safe_sparse_dot(t, self.target_components_) + self.intercept_hidden_).sum(axis=1)\n",
    "            elif (self.target_dist == 'gaussian'):\n",
    "                target_energy = np.sum((t / self.target_sigma) ** 2, axis=1) - np.logaddexp(0, safe_sparse_dot(t/(self.target_sigma ** 2), self.target_components__)).sum(axis=1)\n",
    "            elif (self.target_dist == 'bernoulli'):\n",
    "                target_energy = - np.logaddexp(0, safe_sparse_dot(t, self.target_components_)).sum(axis=1)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid target distribution: {}\".format(self.target_dist))\n",
    "        else:\n",
    "            target_energy = 0.\n",
    "        return input_energy + target_energy\n",
    "\n",
    "    def gibbs(self, v, t):\n",
    "        \"\"\"Perform one Gibbs sampling step.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        v : ndarray of shape (n_samples, n_features)\n",
    "            Values of the visible layer to start from.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        v_new : ndarray of shape (n_samples, n_features)\n",
    "            Values of the visible layer after one Gibbs step.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self)\n",
    "        if not hasattr(self, \"random_state_\"):\n",
    "            self.random_state_ = check_random_state(self.random_state)\n",
    "        h_ = self._sample_hiddens(v, t, self.random_state_)\n",
    "        v_ = self._sample_visibles(h_, self.random_state_)\n",
    "        t_ = self._sample_targets(h_, self.random_state_)\n",
    "\n",
    "        return v_, t_\n",
    "\n",
    "    @_fit_context(prefer_skip_nested_validation=True)\n",
    "    def partial_fit(self, X, y=None):\n",
    "        \"\"\"Fit the model to the partial segment of the data X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, n_features)\n",
    "            Training data.\n",
    "\n",
    "        y : array-like of shape (n_samples,) or (n_samples, n_outputs), default=None\n",
    "            Target values (None for unsupervised transformations).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : BernoulliRBM\n",
    "            The fitted model.\n",
    "        \"\"\"\n",
    "        first_pass = not hasattr(self, \"components_\")\n",
    "        X = self._validate_data(\n",
    "            X, accept_sparse=\"csr\", dtype=np.float64, reset=first_pass\n",
    "        )\n",
    "        if not hasattr(self, \"random_state_\"):\n",
    "            self.random_state_ = check_random_state(self.random_state)\n",
    "        if not hasattr(self, \"components_\"):\n",
    "            self.components_ = np.asarray(\n",
    "                self.random_state_.normal(0, 0.01, (self.n_components, X.shape[1])),\n",
    "                order=\"F\",\n",
    "            )\n",
    "            self._n_features_out = self.components_.shape[0]\n",
    "        if not hasattr(self, \"intercept_hidden_\"):\n",
    "            self.intercept_hidden_ = np.zeros(\n",
    "                self.n_components,\n",
    "            )\n",
    "        if not hasattr(self, \"intercept_visible_\"):\n",
    "            self.intercept_visible_ = np.zeros(\n",
    "                X.shape[1],\n",
    "            )\n",
    "        if not hasattr(self, \"h_samples_\"):\n",
    "            self.h_samples_ = np.zeros((self.batch_size, self.n_components))\n",
    "\n",
    "        self._fit(X, y, self.random_state_)\n",
    "\n",
    "    def _fit(self, v_pos, t_pos, rng):\n",
    "        \"\"\"Inner fit for one mini-batch.\n",
    "\n",
    "        Adjust the parameters to maximize the likelihood of v using\n",
    "        Stochastic Maximum Likelihood (SML).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        v_pos : ndarray of shape (n_samples, n_features)\n",
    "            The data to use for training.\n",
    "\n",
    "        rng : RandomState instance\n",
    "            Random number generator to use for sampling.\n",
    "        \"\"\"\n",
    "        h_pos = self._mean_hiddens(v_pos, t_pos)\n",
    "        v_neg = self._sample_visibles(self.h_samples_, rng)\n",
    "        t_neg = self._sample_targets(self.h_samples_, rng)\n",
    "        h_neg = self._mean_hiddens(v_neg, t_neg)\n",
    "        \n",
    "\n",
    "        lr = float(self.learning_rate) / v_pos.shape[0]\n",
    "        update = safe_sparse_dot(v_pos.T, h_pos, dense_output=True).T\n",
    "        update -= np.dot(h_neg.T, v_neg)\n",
    "        self.components_ += lr * update\n",
    "        self.intercept_hidden_ += lr * (h_pos.sum(axis=0) - h_neg.sum(axis=0))\n",
    "        self.intercept_visible_ += lr * (\n",
    "            np.asarray(v_pos.sum(axis=0)).squeeze() - v_neg.sum(axis=0)\n",
    "        )\n",
    "\n",
    "        if (self.target_in_model):\n",
    "            update_target = safe_sparse_dot(h_pos.T, t_pos/self.target_sigma, dense_output=True).T\n",
    "            update_target -= np.dot(h_neg.T, t_neg/self.target_sigma).T\n",
    "            self.target_components_ += lr/100. * update_target\n",
    "            self.intercept_target_ += lr/100. * (np.sum(t_pos/(self.target_sigma**2), axis=0) - np.sum(t_neg/(self.target_sigma**2), axis=0))\n",
    "\n",
    "        if (self.latent_dist == 'multinomial'):\n",
    "            self.h_samples_ = [rng.multinomial(self.sample_size, pval) for pval in h_neg]\n",
    "            self.h_samples_ = np.array(self.h_samples_)\n",
    "        elif (self.latent_dist == 'bernoulli'):\n",
    "            h_neg[rng.uniform(size=h_neg.shape) < h_neg] = 1.0  # sample binomial\n",
    "            self.h_samples_ = np.floor(h_neg, h_neg)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid latent distribution: {}\".format(self.latent_dist))\n",
    "\n",
    "    def score_samples(self, X, y):\n",
    "        \"\"\"Compute the pseudo-likelihood of X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            Values of the visible layer. Must be all-boolean (not checked).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pseudo_likelihood : ndarray of shape (n_samples,)\n",
    "            Value of the pseudo-likelihood (proxy for likelihood).\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        This method is not deterministic: it computes a quantity called the\n",
    "        free energy on X, then on a randomly corrupted version of X, and\n",
    "        returns the log of the logistic function of the difference.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        v = self._validate_data(X, accept_sparse=\"csr\", reset=False)\n",
    "        t = self._validate_data(y, accept_sparse=\"csr\", reset=False)\n",
    "        rng = check_random_state(self.random_state)\n",
    "\n",
    "        # Randomly corrupt one feature in each sample in v.\n",
    "        ind = (np.arange(v.shape[0]), rng.randint(0, v.shape[1], v.shape[0]))\n",
    "        if sp.issparse(v):\n",
    "            data = -2 * v[ind] + 1\n",
    "            if isinstance(data, np.matrix):  # v is a sparse matrix\n",
    "                v_ = v + sp.csr_matrix((data.A.ravel(), ind), shape=v.shape)\n",
    "            else:  # v is a sparse array\n",
    "                v_ = v + sp.csr_array((data.ravel(), ind), shape=v.shape)\n",
    "        else:\n",
    "            v_ = v.copy()\n",
    "            v_[ind] = 1 - v_[ind]\n",
    "\n",
    "        fe = self._free_energy(v, t)\n",
    "        fe_ = self._free_energy(v_, t)\n",
    "        # log(expit(x)) = log(1 / (1 + exp(-x)) = -np.logaddexp(0, -x)\n",
    "        return -v.shape[1] * np.logaddexp(0, -(fe_ - fe))\n",
    "\n",
    "    @_fit_context(prefer_skip_nested_validation=True)\n",
    "    def fit(self, X, y, sample_size=100):\n",
    "        \"\"\"Fit the model to the data X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            Training data.\n",
    "\n",
    "        y : array-like of shape (n_samples,) or (n_samples, n_outputs).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : BernoulliRBM\n",
    "            The fitted model.\n",
    "        \"\"\"\n",
    "        X = self._validate_data(X, accept_sparse=\"csr\", dtype=(np.float64, np.float32))\n",
    "        y = self._validate_data(y, accept_sparse=\"csr\", dtype=(np.float64, np.float32))\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        rng = check_random_state(self.random_state)\n",
    "\n",
    "        self.sample_size = sample_size\n",
    "        self.components_ = np.asarray(\n",
    "            rng.normal(0, 0.01, (self.n_components, X.shape[1])),\n",
    "            order=\"F\",\n",
    "            dtype=X.dtype,\n",
    "        )\n",
    "        self.sigma = 0.1\n",
    "        self.target_sigma = 0.1\n",
    "        self.target_components_ = np.asarray(\n",
    "            rng.normal(0, 0.01, (y.shape[1], self.n_components)),\n",
    "            order=\"F\",\n",
    "            dtype=y.dtype,\n",
    "        )\n",
    "            \n",
    "        self.intercept_target_ = np.zeros(y.shape[1], dtype=y.dtype)\n",
    "        self._n_features_out = self.components_.shape[0]\n",
    "        self.intercept_hidden_ = np.zeros(self.n_components, dtype=X.dtype)\n",
    "        self.intercept_visible_ = np.zeros(X.shape[1], dtype=X.dtype)\n",
    "        self.h_samples_ = np.zeros((self.batch_size, self.n_components), dtype=X.dtype)\n",
    "\n",
    "        n_batches = int(np.ceil(float(n_samples) / self.batch_size))\n",
    "        batch_slices = list(\n",
    "            gen_even_slices(n_batches * self.batch_size, n_batches, n_samples=n_samples)\n",
    "        )\n",
    "        verbose = self.verbose\n",
    "        begin = time.time()\n",
    "        for iteration in range(1, self.n_iter + 1):\n",
    "            for batch_slice in batch_slices:\n",
    "                self._fit(X[batch_slice], y[batch_slice], rng)\n",
    "\n",
    "            if verbose:\n",
    "                end = time.time()\n",
    "                print(\n",
    "                    \"[%s] Iteration %d, pseudo-likelihood = %.2f, time = %.2fs\"\n",
    "                    % (\n",
    "                        type(self).__name__,\n",
    "                        iteration,\n",
    "                        self.score_samples(X).mean(),\n",
    "                        end - begin,\n",
    "                    )\n",
    "                )\n",
    "                begin = end\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _more_tags(self):\n",
    "        return {\n",
    "            \"_xfail_checks\": {\n",
    "                \"check_methods_subset_invariance\": (\n",
    "                    \"fails for the decision_function method\"\n",
    "                ),\n",
    "                \"check_methods_sample_order_invariance\": (\n",
    "                    \"fails for the score_samples method\"\n",
    "                ),\n",
    "            },\n",
    "            \"preserves_dtype\": [np.float64, np.float32],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9d5a23-6c00-4d70-a96d-ee43cbade143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_points_to_simplex(points):\n",
    "    \"\"\"\n",
    "    Projects each point in a multidimensional cube [0, 1]^n onto the n-dimensional simplex.\n",
    "\n",
    "    Parameters:\n",
    "        points (np.ndarray): A 2D numpy array where each row is a point in the hypercube [0, 1]^n.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 2D numpy array with each row projected onto the n-dimensional simplex.\n",
    "    \"\"\"\n",
    "    # Number of points and dimension\n",
    "    num_points, dim = points.shape\n",
    "    \n",
    "    # Array to store the projected points\n",
    "    projected_points = np.zeros_like(points)\n",
    "    \n",
    "    for i in range(num_points):\n",
    "        point = points[i]\n",
    "        \n",
    "        # Step 1: Sort the point in descending order\n",
    "        u = np.sort(point)[::-1]\n",
    "        \n",
    "        # Step 2: Find the largest k such that the projection condition holds\n",
    "        cumulative_sum = np.cumsum(u)\n",
    "        rho = np.where(u > (cumulative_sum - 1) / (np.arange(dim) + 1))[0][-1]\n",
    "        \n",
    "        # Step 3: Compute theta\n",
    "        theta = (cumulative_sum[rho] - 1) / (rho + 1)\n",
    "        \n",
    "        # Step 4: Project point onto the simplex\n",
    "        projected_points[i] = np.maximum(point - theta, 0)\n",
    "    \n",
    "    return projected_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f776ae65-b121-4698-96a6-4950c823bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import binarize\n",
    "\n",
    "# Load the MNIST dataset from OpenML\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "\n",
    "# Extract features and labels\n",
    "X, y = mnist['data'], mnist['target']\n",
    "y = y.astype(np.int32)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Preprocess the data\n",
    "X_train = X_train.reshape(-1, 784) / 255.0  # Normalize to [0,1] and flatten\n",
    "X_test = X_test.reshape(-1, 784) / 255.0\n",
    "y_train_input = y_train.reshape(X_train.shape[0], -1) / 10.0\n",
    "y_test_input = y_test.reshape(y_test.shape[0], -1) / 10.0\n",
    "\n",
    "# Binarize the images, as RBMs work best with binary input\n",
    "X_train_bin = binarize(X_train, threshold=0.5)\n",
    "X_test_bin = binarize(X_test, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a311e6ff-bfbe-43d1-9376-f2fb0db58366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt    \n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5da12d5-dc16-4d7c-b402-e613b20ea648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RBM(learning_rate=0.06, n_components=128, random_state=0, target_in_model=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RBM<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RBM(learning_rate=0.06, n_components=128, random_state=0, target_in_model=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RBM(learning_rate=0.06, n_components=128, random_state=0, target_in_model=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm = RBM(n_components=128, learning_rate=0.06, n_iter=10, verbose=0, random_state=0, add_bias=False, target_in_model=True, input_dist='bernoulli', latent_dist='bernoulli', target_dist='gaussian')\n",
    "# # Treat warnings as errors\n",
    "# warnings.simplefilter(\"error\")\n",
    "\n",
    "# Fit RBM to the MNIST training data\n",
    "rbm.fit(X_train_bin, y_train_input)\n",
    "\n",
    "# Extract embeddings (transform) for train and test sets\n",
    "X_train_embedded = rbm.transform(X_train_bin, y_train_input)\n",
    "X_test_embedded = rbm.transform(X_test_bin, y_test_input)\n",
    "X_train_simplex = project_points_to_simplex(X_train_embedded)\n",
    "X_test_simplex = project_points_to_simplex(X_test_embedded)\n",
    "\n",
    "# Initialize UMAP with desired parameters\n",
    "umap = UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "warnings.simplefilter(\"default\")\n",
    "# Fit and transform the data\n",
    "X_train_umap = umap.fit_transform(X_train_embedded)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X_train_umap[:, 0], X_train_umap[:, 1], c=y_train, cmap=\"Spectral\", s=1, alpha=0.6)\n",
    "plt.colorbar(scatter, label=\"Digit Label\")\n",
    "plt.title(\"UMAP RBM Embedding of MNIST Training Data\")\n",
    "plt.xlabel(\"UMAP Dimension 1\")\n",
    "plt.ylabel(\"UMAP Dimension 2\")\n",
    "plt.show()\n",
    "\n",
    "# Initialize UMAP with desired parameters\n",
    "umap = UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "warnings.simplefilter(\"default\")\n",
    "# Fit and transform the data\n",
    "X_train_umap = umap.fit_transform(X_train_simplex)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X_train_umap[:, 0], X_train_umap[:, 1], c=y_train, cmap=\"Spectral\", s=1, alpha=0.6)\n",
    "plt.colorbar(scatter, label=\"Digit Label\")\n",
    "plt.title(\"UMAP RBM Embedding of Projected MNIST Training Data\")\n",
    "plt.xlabel(\"UMAP Dimension 1\")\n",
    "plt.ylabel(\"UMAP Dimension 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c56958-dd8d-4368-b7d8-708c517ed0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
